{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as utils\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperTokenizer, ViTModel\n",
    "import evaluate\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#############################################\n",
    "########### ë³€ìˆ˜ ì„¤ì • #########################\n",
    "#############################################\n",
    "\n",
    "MAX_STEPS = 50\n",
    "LOG_INTERVER = 1\n",
    "BATCH_SIZE = 5  # í•œ ë²ˆì— 4ê°œì˜ ìŒì„± íŒŒì¼ì„ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì •\n",
    "\n",
    "# EPSILON = 0.0001 # SPSA Perturbation í¬ê¸°\n",
    "# ALPHA = 0.602 # SPSA Learning rate scaling 0.602\n",
    "# GAMMA = 0.101  # SPSA Decay 0.101\n",
    "# AK=0.0004 \n",
    "# CK=0.000025 # gradient ì¶”ì •ì‹œ ì‚¬ìš© ê°’\n",
    "# O=10\n",
    "# P_TRIGGER_EPSILON = 0.00000005 # p_trigger ì—…ë°ì´íŠ¸ì‹œ ì‚¬ìš©\n",
    "\n",
    "EPSILON = 0.001  # ê¸°ì¡´ë³´ë‹¤ 10ë°° ì¦ê°€\n",
    "ALPHA = 0.602\n",
    "GAMMA = 0.101\n",
    "AK = 0.00001  # ê¸°ì¡´ë³´ë‹¤ 25ë°° ì¦ê°€\n",
    "CK = 0.005  # ê¸°ì¡´ë³´ë‹¤ 5ë°° ì¦ê°€\n",
    "O = 7  # ê¸°ì¡´ë³´ë‹¤ ê°ì†Œ\n",
    "P_TRIGGER_EPSILON = 0.0000001  # ê¸°ì¡´ë³´ë‹¤ 10ë°° ì¦ê°€\n",
    "\n",
    "MAX_GRAD = 3000 # Gradient clipping ì œí•œì¹˜\n",
    "\n",
    "\n",
    "# LOSS_FN = \"wer\"  # WER ê¸°ë°˜ Loss\n",
    "LOSS_FN = \"cross entropy\"  # Loss ìœ í˜•\n",
    "MAX_FRAMES = 3000\n",
    "meshgrid_HIDDEN_DIM = 768  # ViT hidden_dim\n",
    "MAX_NEW_TOKENS = 444  # Whisper default Max Tokens 448 - 4. 4: decoder_input_ids ê°œìˆ˜\n",
    "ENCODER_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "# whisper_version = \"openai/whisper-large-v3\"\n",
    "whisper_version = \"openai/whisper-small\"\n",
    "\n",
    "if whisper_version == \"openai/whisper-small\":\n",
    "    NUM_MEL_BINS = 80\n",
    "elif whisper_version == \"openai/whisper-large-v3\":\n",
    "    NUM_MEL_BINS = 128\n",
    "else:\n",
    "    raise ValueError(\"ìœ„ìŠ¤í¼ ë²„ì „ í™•ì¸ í•„ìš”\")\n",
    "\n",
    "#############################################\n",
    "#############################################\n",
    "\n",
    "\n",
    "#############################################\n",
    "#####  MeshGridMask (Binary Mask) #####\n",
    "#############################################\n",
    "\n",
    "# âœ… **MeshGridMask: í•„í„° ìƒì„± (0 ë˜ëŠ” 1)**\n",
    "class MeshGridMask(nn.Module):\n",
    "    def __init__(self, mel_bins, frames):\n",
    "        super(MeshGridMask, self).__init__()\n",
    "        # í•„í„°ëŠ” (mel_bins, frames) í¬ê¸°ì´ë©° í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¡œ ì„¤ì •ë¨\n",
    "        self.filter = nn.Parameter(torch.randint(0, 2, (mel_bins, frames), dtype=torch.float32), requires_grad=False)  # 0 ë˜ëŠ” 1 ì´ˆê¸°ê°’\n",
    "\n",
    "    def forward(self, mel):\n",
    "        \"\"\"\n",
    "        mel: (batch_size, mel_bins, frames)\n",
    "        filter: (mel_bins, frames) â†’ í™•ì¥í•˜ì—¬ ë°°ì¹˜ ì°¨ì› ì ìš©\n",
    "        \"\"\"\n",
    "        return mel * self.filter  # í•„í„°ë§ëœ mel spectrogram\n",
    "\n",
    "############################\n",
    "\n",
    "# meshgrid ì´ˆê¸°í™”\n",
    "meshgrid = MeshGridMask(mel_bins=NUM_MEL_BINS, frames=MAX_FRAMES).to(device)\n",
    "\n",
    "\n",
    "############################\n",
    "###### ì—…ë°ì´íŠ¸ ë¡œì§ ì„¤ì • ######\n",
    "############################\n",
    "\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "normalizer = EnglishTextNormalizer() # normalizer ì ìš©\n",
    "\n",
    "# def calculate_wer(references, predictions): \n",
    "#     return wer_metric.compute(references=references, predictions=predictions)\n",
    "\n",
    "def calculate_wer(references, predictions, tokenizer):\n",
    "    \"\"\"\n",
    "    íŒ¨ë”©ëœ labelsë¥¼ ë¬´ì‹œí•˜ê³  WERì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  # Gradient ì €ì¥ ë°©ì§€\n",
    "        filtered_references = []\n",
    "        \n",
    "        # íŒ¨ë”©ì„ ì œì™¸í•œ ì›ë³¸ labels ì¶”ì¶œ & list of characters â†’ list of words ë³€í™˜\n",
    "        for ref in references:\n",
    "            ref_filtered = [word for word in ref if word != tokenizer.pad_token_id]\n",
    "            filtered_references.append(\"\".join(ref_filtered))  # ğŸ”¹ join()ì„ ì‚¬ìš©í•´ ë¬¸ì ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "\n",
    "        # âœ… ë¦¬ìŠ¤íŠ¸ì˜ ê° ìš”ì†Œì— `normalizer()` ì ìš©\n",
    "        filtered_references = [\"\".join(ref_filtered) for ref_filtered in filtered_references]  # ë¦¬ìŠ¤íŠ¸ -> ë¬¸ìì—´ ë³€í™˜\n",
    "        filtered_references = [normalizer(ref) for ref in filtered_references]  # ì •ìƒí™” ì ìš©\n",
    "        predictions = [normalizer(pred) for pred in predictions]  # ì •ìƒí™” ì ìš©\n",
    "\n",
    "    # âœ… ì •ìƒí™”ëœ ë°ì´í„°ë¥¼ WER ê³„ì‚°ì— ì‚¬ìš©\n",
    "    return wer_metric.compute(references=filtered_references, predictions=predictions)\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_cross_entropy_loss(whisper_model, mel_with_delta, labels):\n",
    "    \"\"\"\n",
    "    mel_with_delta: meshgridì™€ ê²°í•©ëœ Mel Spectrogram\n",
    "    labels: ground truth token IDs\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  # Gradient ì €ì¥ ë°©ì§€\n",
    "        outputs = whisper_model(input_features=mel_with_delta, labels=labels)\n",
    "    return outputs.loss  # CrossEntropy loss\n",
    "\n",
    "# SPSA ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (Trigger Vector + Decoder í•™ìŠµ)\n",
    "# ë””ì½”ë” ì „ì²´ë¥¼ ë²¡í„°í™”í•˜ì—¬ perturbation í›„, ë‹¤ì‹œ ë²¡í„°ì—ì„œ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜\n",
    "\n",
    "\n",
    "class SPSA:\n",
    "    def __init__(self, epsilon=0.01, epsilon_decay=0.99, min_epsilon=0.0001):\n",
    "        \"\"\"\n",
    "        epsilon: ì´ˆê¸° perturbation í¬ê¸°\n",
    "        epsilon_decay: ë§¤ stepë§ˆë‹¤ epsilonì„ ì¤„ì´ëŠ” ê°ì‡ ìœ¨ (0 < epsilon_decay < 1)\n",
    "        min_epsilon: epsilonì˜ ìµœì†Œê°’ (ë„ˆë¬´ ì‘ì•„ì§€ì§€ ì•Šë„ë¡ ì œí•œ)\n",
    "        \"\"\"\n",
    "        super(SPSA, self).__init__()   \n",
    "        self.epsilon_0 = epsilon\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.step_count = 0  # í˜„ì¬ ìŠ¤í…\n",
    "\n",
    "    def parameter_update(self):\n",
    "        \"\"\" epsilonì„ ê°ì†Œì‹œí‚¤ëŠ” ì—…ë°ì´íŠ¸ \"\"\"\n",
    "        self.step_count += 1\n",
    "        self.epsilon = max(self.epsilon_0 * (self.epsilon_decay ** self.step_count), self.min_epsilon)\n",
    "\n",
    "    def spsa_update(self, meshgrid, whisper_model, mel: list, labels: list):\n",
    " \n",
    "        torch.cuda.empty_cache()  # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬\n",
    "      \n",
    "        # **1. í•„í„° íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì˜¤ê¸°**\n",
    "        filter_params = meshgrid.filter.detach().clone()  # âœ… meshgrid.filterì—ì„œ ì§ì ‘ ë³µì‚¬                \n",
    "\n",
    "\n",
    "        # Perturbation ë°©ì‹ ë³€ê²½ (ì¼ë¶€ ê°’ë§Œ 0â†”1ë¡œ ë³€ê²½)\n",
    "        num_to_flip = int(self.epsilon * filter_params.numel())  # ì—…ë°ì´íŠ¸í•  ê°œìˆ˜ ê²°ì •\n",
    "        \n",
    "        # ì„œë¡œ ë‹¤ë¥¸ perturbationì„ ì ìš©í•˜ë„ë¡ ë‘ ê°œì˜ indices ìƒì„±\n",
    "        indices_1 = torch.randint(0, meshgrid_params.numel(), (num_to_flip,), device=device)\n",
    "        indices_2 = torch.randint(0, meshgrid_params.numel(), (num_to_flip,), device=device)\n",
    "\n",
    "        # í•„í„° 1 ì ìš©\n",
    "        filter_1 = meshgrid_params.clone()\n",
    "        filter_1.view(-1)[indices_1] = 1 - filter_1.view(-1)[indices_1]  # ê¸°ì¡´ ê°’ ë°˜ì „\n",
    "        mel_filtered_1 = mel * filter_1.unsqueeze(0)\n",
    "\n",
    "        # í•„í„° 2 ì ìš©\n",
    "        filter_2 = meshgrid_params.clone()\n",
    "        filter_2.view(-1)[indices_2] = 1 - filter_2.view(-1)[indices_2]  # ê¸°ì¡´ ê°’ ë°˜ì „\n",
    "        mel_filtered_2 = mel * filter_2.unsqueeze(0)\n",
    "\n",
    "        predictions_1 = whisper_model.generate(input_features=mel_filtered_1, max_new_tokens=MAX_NEW_TOKENS)\n",
    "        predictions_2 = whisper_model.generate(input_features=mel_filtered_2, max_new_tokens=MAX_NEW_TOKENS)\n",
    "\n",
    "        ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        pred_1_texts = tokenizer.batch_decode(predictions_1, skip_special_tokens=True)\n",
    "        pred_2_texts = tokenizer.batch_decode(predictions_2, skip_special_tokens=True)\n",
    "\n",
    "        print(\"Ref\", ref_texts)\n",
    "        print(\"Pred_1\",pred_1_texts)\n",
    "        print(\"Pred_2\",pred_2_texts)\n",
    "\n",
    "\n",
    "        if LOSS_FN == \"wer\":\n",
    "\n",
    "            loss_1 = calculate_wer(ref_texts, pred_1_texts, tokenizer) \n",
    "            loss_2 = calculate_wer(ref_texts, pred_2_texts, tokenizer) \n",
    "\n",
    "        elif LOSS_FN == \"cross entropy\":\n",
    "\n",
    "            loss_1 = calculate_cross_entropy_loss(whisper_model, mel_filtered_1, labels)\n",
    "            loss_2 = calculate_cross_entropy_loss(whisper_model, mel_filtered_2, labels)\n",
    "        else:\n",
    "            raise ValueError(\"Loss function not supported\")\n",
    "\n",
    "        if loss_1 < loss_2:\n",
    "            meshgrid.filter.data.copy_(filter_1)  # Gradient tracking ìœ ì§€\n",
    "        else:\n",
    "            meshgrid.filter.data.copy_(filter_2)  # Gradient tracking ìœ ì§€\n",
    "\n",
    "        return loss_1, loss_2\n",
    "\n",
    "\n",
    "#########################################\n",
    "####### Whisper ëª¨ë¸ ë¡œë“œ ë° Freeze ########\n",
    "#########################################\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(whisper_version)\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(whisper_version).to(device)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(whisper_version, language=\"en\", task=\"transcribe\")\n",
    "\n",
    " # Whisper ëª¨ë¸ Freeze\n",
    "for param in whisper_model.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "######### ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ì´ˆê¸°í™” #########\n",
    "#######################################\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_ID = \"Jzuluaga/atcosim_corpus\"\n",
    "dataset = load_dataset(DATASET_ID, \"default\", split=\"train[:2%]\")  # ë°ì´í„° ì¼ë¶€ë§Œ ì‚¬ìš©\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "def preprocess_data(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    mel = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    labels = processor.tokenizer(batch[\"text\"], return_tensors=\"pt\", padding=\"longest\").input_ids.squeeze(0)\n",
    "    return {\"mel\": torch.tensor(mel, dtype=torch.float32).unsqueeze(0).to(device), \"labels\": labels.to(device)}\n",
    "\n",
    "    \n",
    "processed_dataset = [preprocess_data(item) for item in dataset]\n",
    "\n",
    "# CustomDataset ë° DataLoader ì •ì˜\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "\n",
    "# âœ… collate_fn ì •ì˜ â†’ ë‹¤ë¥¸ ê¸¸ì´ì˜ labels ì²˜ë¦¬\n",
    "def collate_fn(batch):\n",
    "    mel_batch = torch.stack([item[\"mel\"].squeeze(0) for item in batch])  # Mel-Spectrogram ë°°ì¹˜í™”\n",
    "    labels_batch = [item[\"labels\"] for item in batch]  # Labels ë¦¬ìŠ¤íŠ¸ë¡œ ìœ ì§€\n",
    "\n",
    "    # âœ… ê°€ì¥ ê¸´ labelsì— ë§ê²Œ íŒ¨ë”©\n",
    "    labels_padded = pad_sequence(labels_batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return {\"mel\": mel_batch, \"labels\": labels_padded}\n",
    "\n",
    "# âœ… DataLoader ì ìš© (ë°°ì¹˜ í¬ê¸° ì§€ì •)\n",
    "dataset = CustomDataset(processed_dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)  # âœ… collate_fn ì¶”ê°€\n",
    "\n",
    "###################\n",
    "##### í•™ìŠµ ë£¨í”„ #####\n",
    "###################\n",
    "\n",
    "print(\"Update method: \", LOSS_FN)\n",
    "spsa = SPSA(alpha=ALPHA, gamma=GAMMA, epsilon=EPSILON, ak=AK, ck=CK, o=O, p_trigger_epsilon=P_TRIGGER_EPSILON)\n",
    "avg_losses = []\n",
    "\n",
    "for epoch in range(MAX_STEPS):  # MAX_STEPS ë§Œí¼ ë°˜ë³µ\n",
    "    total_loss = 0.0 \n",
    "    num_batches = 0  # ë°°ì¹˜ ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "\n",
    "    for batch in dataloader:\n",
    "        mel = batch[\"mel\"].to(device)  # ë°°ì¹˜ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜\n",
    "        labels = batch[\"labels\"].to(device)  # íŒ¨ë”©ëœ labels í…ì„œ ë³€í™˜\n",
    "\n",
    "        loss_1, loss_2 = spsa.spsa_update(meshgrid, whisper_model, mel, labels)\n",
    "\n",
    "        loss = min(loss_1, loss_2)  # ë” ì‘ì€ Loss ì„ íƒ\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "\n",
    "        spsa.parameter_update()  # epsilon ê°ì†Œ\n",
    "\n",
    "    # í•´ë‹¹ ì—í­ì˜ í‰ê·  Loss ê³„ì‚°\n",
    "    avg_loss = total_loss / (num_batches * BATCH_SIZE)\n",
    "    avg_losses.append(avg_loss)\n",
    "\n",
    "    print()\n",
    "    print(f\"Epoch {epoch}: Avg WER Loss = {avg_loss:.4f}--------------------%%%%%%%%%%%%%%%%%%%@@@@@@@@@@@@@@@+++++++++++++++++++++\")\n",
    "    print()\n",
    "\n",
    "    if epoch >= MAX_STEPS:\n",
    "        break\n",
    "\n",
    "# í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥\n",
    "torch.save(meshgrid.state_dict(), \"meshgrid.pth\")\n",
    "print(\"meshgrid saved!\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GPU í…ì„œë¥¼ CPUë¡œ ì˜®ê¸´ í›„ NumPy ë°°ì—´ë¡œ ë³€í™˜\n",
    "avg_losses_cpu = [loss.cpu().item() if isinstance(loss, torch.Tensor) else loss for loss in avg_losses]\n",
    "\n",
    "plt.plot(avg_losses_cpu)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(f'Average {LOSS_FN}')\n",
    "plt.title(f'Average {LOSS_FN} Over Epochs')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
