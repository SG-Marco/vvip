import torch
import torch.nn as nn
import torch.nn.utils as utils
from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperTokenizer, ViTModel
import evaluate

# GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

#############################################
########### ë³€ìˆ˜ ì„¤ì • #########################
#############################################

MAX_STEPS = 50
LOG_INTERVER = 1
BATCH_SIZE = 5  # í•œ ë²ˆì— 4ê°œì˜ ìŒì„± íŒŒì¼ì„ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì •

# EPSILON = 0.0001 # SPSA Perturbation í¬ê¸°
# ALPHA = 0.602 # SPSA Learning rate scaling 0.602
# GAMMA = 0.101  # SPSA Decay 0.101
# AK=0.0004 
# CK=0.000025 # gradient ì¶”ì •ì‹œ ì‚¬ìš© ê°’
# O=10
# P_TRIGGER_EPSILON = 0.00000005 # p_trigger ì—…ë°ì´íŠ¸ì‹œ ì‚¬ìš©

EPSILON = 0.001  # ê¸°ì¡´ë³´ë‹¤ 10ë°° ì¦ê°€
ALPHA = 0.602
GAMMA = 0.101
AK = 0.00001  # ê¸°ì¡´ë³´ë‹¤ 25ë°° ì¦ê°€
CK = 0.005  # ê¸°ì¡´ë³´ë‹¤ 5ë°° ì¦ê°€
O = 7  # ê¸°ì¡´ë³´ë‹¤ ê°ì†Œ
P_TRIGGER_EPSILON = 0.0000001  # ê¸°ì¡´ë³´ë‹¤ 10ë°° ì¦ê°€

MAX_GRAD = 3000 # Gradient clipping ì œí•œì¹˜

'''íŒŒë¼ë¯¸í„°	ì˜ë¯¸	ì¼ë°˜ì ì¸ ê°’
Î± (alpha)	í•™ìŠµë¥  ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜	0.602 (ê¸°ë³¸)
Î³ (gamma)	c_k ê°ì†Œìœ¨ ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜	0.101 (ê¸°ë³¸)
Îµ (epsilon)	Perturbation í¬ê¸°	0.001 ~ 0.01
a_k (learning rate)	ì—…ë°ì´íŠ¸ í¬ê¸°	1.0 ~ 0.1
c_k (perturbation size)	Perturbation ìŠ¤ì¼€ì¼ë§ ê°’	0.1 ~ 0.01
k (sp_avg)	Gradient í‰ê·  ê³„ì‚° ì‹œ ë°˜ë³µ ìˆ˜	1 ~ 10
max_steps	ìµœëŒ€ ì—…ë°ì´íŠ¸ ìŠ¤í… ìˆ˜	100 ~ 10,000
'''

# LOSS_FN = "wer"  # WER ê¸°ë°˜ Loss
LOSS_FN = "cross entropy"  # Loss ìœ í˜•
MAX_FRAMES = 3000
COORDINATOR_HIDDEN_DIM = 768  # ViT hidden_dim
MAX_NEW_TOKENS = 444  # Whisper default Max Tokens 448 - 4. 4: decoder_input_ids ê°œìˆ˜
ENCODER_NAME = "google/vit-base-patch16-224-in21k"

# whisper_version = "openai/whisper-large-v3"
whisper_version = "openai/whisper-small"

if whisper_version == "openai/whisper-small":
    NUM_MEL_BINS = 80
elif whisper_version == "openai/whisper-large-v3":
    NUM_MEL_BINS = 128
else:
    raise ValueError("ìœ„ìŠ¤í¼ ë²„ì „ í™•ì¸ í•„ìš”")

#############################################
#############################################

########################
##### Coordinator ######
########################

'''
ViTëŠ” 3ì±„ë„ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ. ê·¸ë¦¬ê³  16x16 ì‚¬ì´ì¦ˆ íŒ¨ì¹˜ë¡¤ ì²˜ë¦¬í•˜ê¸°ìœ„í•´ 224x224 ì‚¬ì´ì¦ˆë¥¼ ê¸°ëŒ€í•¨.
Mel spectogram ì€ 1ì±„ë„ì´ê³  80x3000(128x3000)ì´ë¯€ë¡œ ì´ ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼í•¨

âœ… ìµœì ì˜ í•´ê²° ë°©ë²•: Conv2d ë³€í™˜ + Conv2d ë³µì›

ğŸ“Œ ì…ë ¥ ë³€í™˜ (1ì±„ë„ â†’ 3ì±„ë„)
	â€¢	Conv2d(in_channels=1, out_channels=3, kernel_size=1)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜.
	â€¢	í•™ìŠµ ê°€ëŠ¥í•œ ë³€í™˜ì´ë¯€ë¡œ ìµœì í™” ê°€ëŠ¥.

ğŸ“Œ ì¶œë ¥ ë³µì› (3ì±„ë„ â†’ 1ì±„ë„)
	â€¢	Conv2d(in_channels=3, out_channels=1, kernel_size=1)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ 1ì±„ë„ë¡œ ë³€í™˜.
	â€¢	Mel Spectrogram ì°¨ì›(1, mel_bins, frames)ì„ ìœ ì§€.

âœ… ì´ ë°©ì‹ì˜ ì¥ì :
âœ” ViT ì…ë ¥ê³¼ Whisper ì¶œë ¥ì„ ëª¨ë‘ ë§Œì¡±
âœ” í•™ìŠµ ê°€ëŠ¥í•œ ë³€í™˜ì´ë¯€ë¡œ ì„±ëŠ¥ ìµœì í™” ê°€ëŠ¥
âœ” Mel Spectrogramì˜ ì •ë³´ ì†ì‹¤ ìµœì†Œí™”

âœ… í•´ê²° ë°©ë²•: Mel Spectrogramì„ ViTê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜

ğŸš€ ë°©ë²• 1: íŒ¨ì¹˜ í¬ê¸° ì¡°ì • (patch_size=16 â†’ ì»¤ìŠ¤í…€ í¬ê¸° ì‚¬ìš©)
	â€¢	ViTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 16Ã—16 íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„í• í•˜ì—¬ ì²˜ë¦¬.
	â€¢	í•˜ì§€ë§Œ Mel Spectrogramì€ ê¸¸ì´ê°€ ê¸¸ê³  ë†’ì´ê°€ ì‘ìŒ â†’ ì¼ë°˜ì ì¸ 16Ã—16 íŒ¨ì¹˜ ë°©ì‹ì´ ì í•©í•˜ì§€ ì•ŠìŒ.
	â€¢	ì»¤ìŠ¤í…€ íŒ¨ì¹˜ í¬ê¸°ë¥¼ ì„¤ì •í•˜ì—¬ 80Ã—3000 ë°ì´í„°ë¥¼ ViTê°€ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜.

ğŸ“Œ ë°©ë²•:
	â€¢	ViTFeatureExtractorì˜ íŒ¨ì¹˜ í¬ê¸°ë¥¼ ì¡°ì • (patch_size=(8, 64))
	â€¢	Mel Spectrogramì„ 80Ã—3000 â†’ 224Ã—224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ ViTì— ì…ë ¥
'''
import torch
import torch.nn as nn
from transformers import ViTModel


class Coordinator(nn.Module):
    def __init__(self, encoder_name="google/vit-base-patch16-224-in21k", mel_bins=80, frames=3000, src_dim=1568, hidden_dim=768):
        super(Coordinator, self).__init__()       
        self.backbone = encoder_name
        act = nn.GELU #if args.TRAINER.BLACKVIP.ACT == 'gelu' else nn.ReLU
        z_dim = hidden_dim

        self.encoder = ViTModel.from_pretrained(encoder_name)

        # âœ… **Mel Spectrogram ë³€í™˜ (1ì±„ë„ â†’ 3ì±„ë„)**
        self.conv1x1_in = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=1)

        # âœ… **Mel Spectrogram í¬ê¸° ë³€í™˜ (80Ã—3000 â†’ 224Ã—224)**
        self.resize = nn.AdaptiveAvgPool2d((224, 224))

        self.dec = DecoderManual(z_dim, src_dim, act=act, arch=self.backbone)

    def forward(self, x):
        with torch.no_grad():
 
            # âœ… **1ì±„ë„ ì¶”ê°€ (batch_size, mel_bins, frames) â†’ (batch_size, 1, mel_bins, frames)**
            if x.dim() == 3:  
                x = x.unsqueeze(1)  # (batch_size, 1, mel_bins, frames)

            # âœ… **1ì±„ë„ â†’ 3ì±„ë„ ë³€í™˜**
            x = self.conv1x1_in(x)  # (batch_size, 3, mel_bins, frames)

            # âœ… **80Ã—3000 â†’ 224Ã—224 í¬ê¸°ë¡œ ë³€í™˜**
            x = self.resize(x)  # (batch_size, 3, 224, 224)

            #! (N, 197, 768) => pick [CLS] => (N, 768)
            out = self.encoder(x)
            z = out.last_hidden_state[:,0,:]
      
        wrap = self.dec(z)
        return z, wrap

class DecoderManual(nn.Module):
    def __init__(self, i_dim, src_dim, act=nn.GELU, arch='vit-base'):
        super(DecoderManual, self).__init__()
        if i_dim:
            self.shared_feature = 1
        else:     self.shared_feature = 0
        if self.shared_feature:
            #! start from 7*7*16(784:16) or 7*7*32(1568:800) or 7*7*64(3,136:2368)
            if (src_dim % 49) != 0: raise ValueError('map dim must be devided with 7*7')
            self.p_trigger = torch.nn.Parameter(torch.Tensor(1, src_dim - i_dim))
            torch.nn.init.uniform_(self.p_trigger, a=0.0, b=0.1) # can be tuned
            src_c = src_dim // 49
        else:
            src_c = src_dim
        
        bias_flag = False
        body_seq = []
        
        if arch in ['vit-mae-base', 'vit-base', "google/vit-base-patch16-224-in21k"]:
            if src_c >= 64:    g_c = 64
            else:              g_c = src_c
            body_seq              +=  [nn.ConvTranspose2d(src_c, 64, 2, 2, 0, groups=g_c),
                                       nn.ConvTranspose2d(64, 64, kernel_size=1, bias=bias_flag)]
            body_seq              +=  [nn.BatchNorm2d(64), act()]
            body_seq              +=  [nn.ConvTranspose2d(64, 64, 2, 2, 0, groups=64),
                                       nn.ConvTranspose2d(64, 32, kernel_size=1, bias=bias_flag)]
            body_seq              +=  [nn.BatchNorm2d(32), act()]
            body_seq              +=  [nn.ConvTranspose2d(32, 32, 2, 2, 0, groups=32),
                                       nn.ConvTranspose2d(32, 32, kernel_size=1, bias=bias_flag)]
            body_seq              +=  [nn.BatchNorm2d(32), act()]
            body_seq              +=  [nn.ConvTranspose2d(32, 32, 2, 2, 0, groups=32),
                                       nn.ConvTranspose2d(32, 16, kernel_size=1, bias=bias_flag)]
            body_seq              +=  [nn.BatchNorm2d(16), act()]
            body_seq              +=  [nn.ConvTranspose2d(16, 3, 2, 2, 0, bias=bias_flag)]  
   
        else: 
            raise ValueError('not implemented')
        self.body   = nn.Sequential(*body_seq)

        # âœ… **3ì±„ë„ â†’ 1ì±„ë„ ë³€í™˜ (ì¶œë ¥)**
        self.conv1x1_out = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1)

        # âœ… **Mel Spectrogram í¬ê¸° ë³€í™˜ (80Ã—3000 â†’ 224Ã—224)**
        self.resize = nn.AdaptiveAvgPool2d((NUM_MEL_BINS, MAX_FRAMES))

    def forward(self, z):
        if self.shared_feature:
            # z.shape = (1, 768)
            N = z.shape[0]
            D = self.p_trigger.shape[1] 
            
            p_trigger = self.p_trigger.repeat(N, 1) # (1, 800)

            z_cube = torch.cat((z, p_trigger), dim=1) # (1, 1568)

            z_cube = z_cube.reshape(N, -1, 7, 7) # (1, 32, 7, 7)

            z_cube = self.body(z_cube) # (1, 3, 224, 224)
     
            # âœ… **224x224 â†’ 80x3000 í¬ê¸°ë¡œ ë³€í™˜**
            z_cube = self.resize(z_cube)  # (batch_size, 3, mel_bins, frames)
     
            # âœ… **3ì±„ë„ â†’ 1ì±„ë„ ë³€í™˜**
            z_cube = self.conv1x1_out(z_cube)  # (batch_size, 1, mel_bins, frames)
  
            # âœ… **1ì±„ë„ ì œê±° (batch_size, mel_bins, frames)**
            z_cube = z_cube.squeeze(1)  # (batch_size, mel_bins, frames)
        else:
            return self.body(z)
        return z_cube


############################

# Coordinator ì´ˆê¸°í™”
coordinator = Coordinator(encoder_name=ENCODER_NAME, mel_bins=NUM_MEL_BINS, frames=MAX_FRAMES, hidden_dim=COORDINATOR_HIDDEN_DIM).to(device)


############################
###### ì—…ë°ì´íŠ¸ ë¡œì§ ì„¤ì • ######
############################

from whisper.normalizers import EnglishTextNormalizer

wer_metric = evaluate.load("wer")
normalizer = EnglishTextNormalizer() # normalizer ì ìš©

# def calculate_wer(references, predictions): 
#     return wer_metric.compute(references=references, predictions=predictions)

def calculate_wer(references, predictions, tokenizer):
    """
    íŒ¨ë”©ëœ labelsë¥¼ ë¬´ì‹œí•˜ê³  WERì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    """
    with torch.no_grad():  # Gradient ì €ì¥ ë°©ì§€
        filtered_references = []
        
        # íŒ¨ë”©ì„ ì œì™¸í•œ ì›ë³¸ labels ì¶”ì¶œ & list of characters â†’ list of words ë³€í™˜
        for ref in references:
            ref_filtered = [word for word in ref if word != tokenizer.pad_token_id]
            filtered_references.append("".join(ref_filtered))  # ğŸ”¹ join()ì„ ì‚¬ìš©í•´ ë¬¸ì ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜

        # âœ… ë¦¬ìŠ¤íŠ¸ì˜ ê° ìš”ì†Œì— `normalizer()` ì ìš©
        filtered_references = ["".join(ref_filtered) for ref_filtered in filtered_references]  # ë¦¬ìŠ¤íŠ¸ -> ë¬¸ìì—´ ë³€í™˜
        filtered_references = [normalizer(ref) for ref in filtered_references]  # ì •ìƒí™” ì ìš©
        predictions = [normalizer(pred) for pred in predictions]  # ì •ìƒí™” ì ìš©

    # âœ… ì •ìƒí™”ëœ ë°ì´í„°ë¥¼ WER ê³„ì‚°ì— ì‚¬ìš©
    return wer_metric.compute(references=filtered_references, predictions=predictions)


import torch.nn.functional as F

def calculate_cross_entropy_loss(whisper_model, mel_with_delta, labels):
    """
    mel_with_delta: Coordinatorì™€ ê²°í•©ëœ Mel Spectrogram
    labels: ground truth token IDs
    """
    with torch.no_grad():  # Gradient ì €ì¥ ë°©ì§€
        outputs = whisper_model(input_features=mel_with_delta, labels=labels)
    return outputs.loss  # CrossEntropy loss

# SPSA ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (Trigger Vector + Decoder í•™ìŠµ)
# ë””ì½”ë” ì „ì²´ë¥¼ ë²¡í„°í™”í•˜ì—¬ perturbation í›„, ë‹¤ì‹œ ë²¡í„°ì—ì„œ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜
'''
âœ… ì¥ì 
	1.	SPSA ìµœì í™”ì˜ ì•ˆì •ì„± ì¦ê°€
	â€¢	ëª¨ë“  ë””ì½”ë” íŒŒë¼ë¯¸í„°ë¥¼ ë‹¨ì¼ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì—…ë°ì´íŠ¸í•˜ë¯€ë¡œ, ê°œë³„ ë ˆì´ì–´ì˜ ë³€í™”ëŸ‰ì„ ê³ ë ¤í•œ ì „ì—­ì ì¸ perturbation ì ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
	â€¢	ì´ëŠ” ê°œë³„ ë ˆì´ì–´ì— ë…ë¦½ì ìœ¼ë¡œ perturbationì„ ì ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ì¼ê´€ëœ ë³€í™” íŒ¨í„´ì„ ìœ ì§€í•˜ë©´ì„œ ìµœì í™”ê°€ ì´ë£¨ì–´ì§€ë„ë¡ í•©ë‹ˆë‹¤.
	2.	Gradient Estimationì´ íš¨ìœ¨ì ìœ¼ë¡œ ì´ë£¨ì–´ì§
	â€¢	ë””ì½”ë” ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì·¨ê¸‰í•˜ì—¬ SPSA Gradientë¥¼ ê·¼ì‚¬í•˜ë¯€ë¡œ, ê°œë³„ íŒŒë¼ë¯¸í„°ë§ˆë‹¤ ë”°ë¡œ ê³„ì‚°í•˜ëŠ” ê²ƒë³´ë‹¤ ì—°ì‚°ëŸ‰ì´ ì¤„ì–´ë“¤ê³  í•™ìŠµì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
	â€¢	íŠ¹íˆ, ë†’ì€ ì°¨ì›ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ëª¨ë¸ì—ì„œëŠ” Gradient ì¶”ì •ì´ ë” ì •í™•í•´ì§ˆ ìˆ˜ ìˆìŒ.
	3.	ì½”ë“œì˜ ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ ìš©ì´
	â€¢	parameters_to_vector()ë¥¼ ì‚¬ìš©í•˜ë©´ ë””ì½”ë” ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì·¨ê¸‰í•  ìˆ˜ ìˆì–´, í•™ìŠµ ì½”ë“œê°€ ê°„ê²°í•´ì§€ê³  ìœ ì§€ë³´ìˆ˜ê°€ ì‰¬ì›Œì§‘ë‹ˆë‹¤.
	â€¢	vector_to_parameters()ë¥¼ ì‚¬ìš©í•˜ë©´ perturbation í›„ ì›ë˜ í˜•íƒœì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¡œ ë‹¤ì‹œ ë³µêµ¬í•  ìˆ˜ ìˆì–´ êµ¬ì¡°ë¥¼ ìœ ì§€í•œ ì±„ ì—…ë°ì´íŠ¸ ê°€ëŠ¥.
	4.	Batch-level ì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥
	â€¢	ê°œë³„ ë ˆì´ì–´ë§ˆë‹¤ perturbationì„ ì ìš©í•˜ëŠ” ë°©ì‹ê³¼ ë‹¬ë¦¬, ë²¡í„°í™”ëœ perturbationì„ ì ìš©í•˜ë©´ batch-levelì—ì„œ ìµœì í™”ê°€ ê°€ëŠ¥.
	â€¢	ì´ëŠ” ë³‘ë ¬ ì—°ì‚° ë° GPU í™œìš©ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ê°€ ë˜ì–´ í•™ìŠµ ì†ë„ê°€ í–¥ìƒë  ìˆ˜ ìˆìŒ.
âŒ ë‹¨ì 
	1.	ëª¨ë¸ì´ ì»¤ì§ˆìˆ˜ë¡ ë©”ëª¨ë¦¬ ë¶€ë‹´ ì¦ê°€
	â€¢	ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ perturbationì„ ì ìš©í•˜ë©´, í° ëª¨ë¸ì—ì„œëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê¸‰ê²©íˆ ì¦ê°€í•  ìˆ˜ ìˆìŒ.
	â€¢	íŠ¹íˆ, ëŒ€ê·œëª¨ Transformer ê¸°ë°˜ ë””ì½”ë”(ì˜ˆ: GPT, BERT)ì—ì„œëŠ” íŒŒë¼ë¯¸í„° ê°œìˆ˜ê°€ ìˆ˜ì–µ ê°œì— ì´ë¥´ê¸° ë•Œë¬¸ì— ë²¡í„°í™”ëœ ë°©ì‹ì´ ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒ.
	2.	SPSA ë°©ì‹ì´ ì¼ë°˜ì ì¸ Gradient Descentë³´ë‹¤ í•™ìŠµ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ
	â€¢	SPSA ìì²´ê°€ Gradientë¥¼ ì§ì ‘ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, Perturbationì„ ì´ìš©í•˜ì—¬ ê·¼ì‚¬í•˜ëŠ” ë°©ì‹ì´ë¯€ë¡œ, ì¼ë°˜ì ì¸ SGDë‚˜ Adamë³´ë‹¤ ì—…ë°ì´íŠ¸ì˜ ì•ˆì •ì„±ì´ ë‚®ì•„ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆìŒ.
	â€¢	ë”°ë¼ì„œ í•™ìŠµ ì´ˆë°˜ì— ìˆ˜ë ´ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ.
	3.	Fine-tuningì— ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
	â€¢	ë””ì½”ë” ì „ì²´ë¥¼ ë²¡í„°í™”í•˜ê³  perturbationì„ ì ìš©í•˜ëŠ” ë°©ì‹ì€ ì„¸ë°€í•œ ì¡°ì •ì´ í•„ìš”í•œ Fine-tuning ë‹¨ê³„ì—ì„œëŠ” ë¶ˆë¦¬í•  ìˆ˜ ìˆìŒ.
	â€¢	íŠ¹ì • Layerë§Œ ë¯¸ì„¸ ì¡°ì •í•˜ë ¤ë©´, Layerë³„ë¡œ perturbationì„ ë‹¤ë¥´ê²Œ ì ìš©í•´ì•¼ í•˜ëŠ”ë°, ë²¡í„°í™”ëœ ë°©ì‹ì—ì„œëŠ” ì´ë¥¼ ìˆ˜í–‰í•˜ê¸° ì–´ë ¤ì›€.
	4.	SPSA ìì²´ì˜ í•œê³„
	â€¢	SPSAëŠ” ìƒ˜í”Œë§ ê¸°ë°˜ Gradient ê·¼ì‚¬ ë°©ì‹ì´ë¯€ë¡œ, ì •í™•í•œ Gradient Descentë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ.
	â€¢	íŠ¹íˆ, Loss Surfaceê°€ ë§¤ìš° ë³µì¡í•œ ê²½ìš°, SPSAê°€ ì§€ì—­ ìµœì†Œì (Local Minima)ì— ë¹ ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.
'''

class SPSA:
    def __init__(self, alpha=0.602, gamma=0.101, epsilon=0.01, ak=0.8, ck=0.05, o=0.01, p_trigger_epsilon=0.01):
        super(SPSA, self).__init__()   
        self.alpha = alpha
        self.gamma = gamma
        self.epsilon = epsilon
        self.ak = ak
        self.ck = ck
        self.o = o
        self.p_trigger_epsilon = p_trigger_epsilon


    def parameter_update(self, step):
        self.ak = self.ak / ((step + self.o)**self.alpha)
        self.ck = self.ck / (step**self.gamma)


    def spsa_update(self, coordinator, whisper_model, mel: list, labels: list):
        """
        coordinator: Coordinator instance
        whisper_model: Whisper ëª¨ë¸ (frozen)
        mel: ì›ë³¸ Mel Spectrogram (batch_size, mel_bins, frames)
        labels: Ground Truth ë¼ë²¨
        """
        torch.cuda.empty_cache()  # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬

        # **1. ë””ì½”ë” ì „ì²´ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë²¡í„°í™”**
        coordinator_params = torch.nn.utils.parameters_to_vector(coordinator.dec.parameters()).detach()
        
        # **2. ëœë¤ Perturbation ìƒì„±**
        perturb = torch.sign(torch.randn_like(coordinator_params)) * self.epsilon

        # **3. Positive Perturbation ì ìš©**
        perturbed_params = coordinator_params + perturb
        torch.nn.utils.vector_to_parameters(perturbed_params, coordinator.dec.parameters())

        _, mel_transformed = coordinator(mel)  # ì „ì²´ ë°°ì¹˜ ë³€í™˜
        mel_with_delta = mel + mel_transformed  
        if LOSS_FN == "wer":
            # Whisper ëª¨ë¸ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ í˜¸ì¶œ
            predictions = whisper_model.generate(input_features=mel_with_delta, max_new_tokens=MAX_NEW_TOKENS, language="en")

            # ë°°ì¹˜ ë‹¨ìœ„ WER ê³„ì‚°
            ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)
            pred_texts = tokenizer.batch_decode(predictions, skip_special_tokens=True)
            loss_plus = calculate_wer(ref_texts, pred_texts, tokenizer)  # âœ… ë°°ì¹˜ ì „ì²´ WER ê³„ì‚°

        elif LOSS_FN == "cross entropy":
            # Whisper ëª¨ë¸ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ í˜¸ì¶œ
            loss_plus = calculate_cross_entropy_loss(whisper_model, mel_with_delta, labels)
        else:
            raise ValueError("Loss function not supported")

        # **4. Negative Perturbation ì ìš©**

        perturbed_params = coordinator_params - perturb
        torch.nn.utils.vector_to_parameters(perturbed_params, coordinator.dec.parameters())

        _, mel_transformed = coordinator(mel)  # ì „ì²´ ë°°ì¹˜ ë³€í™˜
        mel_with_delta = mel + mel_transformed  

        # Whisper ëª¨ë¸ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ í˜¸ì¶œ
        predictions = whisper_model.generate(input_features=mel_with_delta, max_new_tokens=MAX_NEW_TOKENS, language="en")

        # ë°°ì¹˜ ë‹¨ìœ„ WER ê³„ì‚°
        ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)
        pred_texts = tokenizer.batch_decode(predictions, skip_special_tokens=True)

        print("Ref", ref_texts)
        print("Pred",pred_texts)

        if LOSS_FN == "wer":
            loss_minus = calculate_wer(ref_texts, pred_texts, tokenizer)  # âœ… ë°°ì¹˜ ì „ì²´ WER ê³„ì‚°

        elif LOSS_FN == "cross entropy":
            # Whisper ëª¨ë¸ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ í˜¸ì¶œ
            loss_minus = calculate_cross_entropy_loss(whisper_model, mel_with_delta, labels)
        else:
            raise ValueError("Loss function not supported")

        # ë°°ì¹˜ ë‚´ ëª¨ë“  ìƒ˜í”Œì˜ í‰ê·  gradient ê³„ì‚°
        grad_estimate_avg =  (loss_plus - loss_minus) / (2 * self.ck * perturb)

        # Gradient Clipping ì ìš©
        grad_estimate_avg = torch.clamp(grad_estimate_avg, min=-MAX_GRAD, max=MAX_GRAD)

        # coordinator parameters ì›ë˜ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë³€ê²½
        torch.nn.utils.vector_to_parameters(coordinator_params, coordinator.dec.parameters())

        # SPSA Gradient ê·¼ì‚¬
        print(f"Gradient estimate: {grad_estimate_avg}")

        learning_rate = self.ak

        # **5. Coordinator ì—…ë°ì´íŠ¸**
        # p_triggerì™€ decoderì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê³„ì‚°
        p_trigger_param_num = coordinator.dec.p_trigger.numel()

        # p_triggerì™€ decoderì˜ gradientë¥¼ ë¶„ë¦¬
        p_trigger_grad = grad_estimate_avg[:p_trigger_param_num]  # ì•ë¶€ë¶„ â†’ p_triggerì˜ gradient
        decoder_grad = grad_estimate_avg[p_trigger_param_num:]  # ë’·ë¶€ë¶„ â†’ decoderì˜ gradient

        # **p_trigger ì—…ë°ì´íŠ¸**
        p_trigger_vector = torch.nn.utils.parameters_to_vector([coordinator.dec.p_trigger])  # ê¸°ì¡´ p_trigger ê°’ ë²¡í„°í™”
        p_trigger_update = p_trigger_vector - learning_rate * p_trigger_grad * self.p_trigger_epsilon  # ê¸°ì¡´ ê°’ì—ì„œ ì—…ë°ì´íŠ¸ ê³„ì‚°
        torch.nn.utils.vector_to_parameters(p_trigger_update, [coordinator.dec.p_trigger])  # ì—…ë°ì´íŠ¸ ì ìš©

        # **decoder ì—…ë°ì´íŠ¸**
        decoder_params = [p for name, p in coordinator.dec.named_parameters() if name != "p_trigger"]
        decoder_vector = torch.nn.utils.parameters_to_vector(decoder_params)  # ê¸°ì¡´ decoder ê°’ ë²¡í„°í™”
        decoder_update = decoder_vector - learning_rate * decoder_grad  # ê¸°ì¡´ ê°’ì—ì„œ ì—…ë°ì´íŠ¸ ê³„ì‚°
        torch.nn.utils.vector_to_parameters(decoder_update, decoder_params)  # ì—…ë°ì´íŠ¸ ì ìš©

        return loss_plus, loss_minus, grad_estimate_avg


#########################################
####### Whisper ëª¨ë¸ ë¡œë“œ ë° Freeze ########
#########################################

processor = WhisperProcessor.from_pretrained(whisper_version)
whisper_model = WhisperForConditionalGeneration.from_pretrained(whisper_version).to(device)
tokenizer = WhisperTokenizer.from_pretrained(whisper_version, language="en", task="transcribe")

 # Whisper ëª¨ë¸ Freeze
for param in whisper_model.parameters():
    param.requires_grad = False 



#######################################
######### ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ì´ˆê¸°í™” #########
#######################################

from datasets import load_dataset

DATASET_ID = "Jzuluaga/atcosim_corpus"
dataset = load_dataset(DATASET_ID, "default", split="train[:2%]")  # ë°ì´í„° ì¼ë¶€ë§Œ ì‚¬ìš©

# ë°ì´í„° ì „ì²˜ë¦¬
def preprocess_data(batch):
    audio = batch["audio"]
    mel = processor.feature_extractor(audio["array"], sampling_rate=audio["sampling_rate"]).input_features[0]
    labels = processor.tokenizer(batch["text"], return_tensors="pt", padding="longest").input_ids.squeeze(0)
    return {"mel": torch.tensor(mel, dtype=torch.float32).unsqueeze(0).to(device), "labels": labels.to(device)}

    
processed_dataset = [preprocess_data(item) for item in dataset]

# âœ… CustomDataset ë° DataLoader ì •ì˜
from torch.utils.data import DataLoader, Dataset
from torch.nn.utils.rnn import pad_sequence

class CustomDataset(Dataset):
    def __init__(self, dataset):
        self.dataset = dataset

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        return self.dataset[idx]
    

# âœ… collate_fn ì •ì˜ â†’ ë‹¤ë¥¸ ê¸¸ì´ì˜ labels ì²˜ë¦¬
def collate_fn(batch):
    mel_batch = torch.stack([item["mel"].squeeze(0) for item in batch])  # Mel-Spectrogram ë°°ì¹˜í™”
    labels_batch = [item["labels"] for item in batch]  # Labels ë¦¬ìŠ¤íŠ¸ë¡œ ìœ ì§€

    # âœ… ê°€ì¥ ê¸´ labelsì— ë§ê²Œ íŒ¨ë”©
    labels_padded = pad_sequence(labels_batch, batch_first=True, padding_value=tokenizer.pad_token_id)

    return {"mel": mel_batch, "labels": labels_padded}

# âœ… DataLoader ì ìš© (ë°°ì¹˜ í¬ê¸° ì§€ì •)
dataset = CustomDataset(processed_dataset)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)  # âœ… collate_fn ì¶”ê°€

###################
##### í•™ìŠµ ë£¨í”„ #####
###################

print("Update method: ", LOSS_FN)
spsa = SPSA(alpha=ALPHA, gamma=GAMMA, epsilon=EPSILON, ak=AK, ck=CK, o=O, p_trigger_epsilon=P_TRIGGER_EPSILON)
avg_losses = []

for epoch in range(MAX_STEPS):  # MAX_STEPS ë§Œí¼ ë°˜ë³µ
    total_loss = 0.0 
    num_batches = 0  # ë°°ì¹˜ ê°œìˆ˜ ì¹´ìš´íŠ¸

    for batch in dataloader:
        mel = batch["mel"].to(device)  # ë°°ì¹˜ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜
        labels = batch["labels"].to(device)  # íŒ¨ë”©ëœ labels í…ì„œ ë³€í™˜

        loss_plus, loss_minus, grad_estimate_avg = spsa.spsa_update(coordinator, whisper_model, mel, labels)

        loss = (loss_plus + loss_minus) / 2
        total_loss += loss
        num_batches += 1

        spsa.parameter_update(epoch+1)

    # í•´ë‹¹ ì—í­ì˜ í‰ê·  Loss ê³„ì‚°
    avg_loss = total_loss / (num_batches * BATCH_SIZE)
    avg_losses.append(avg_loss)

    print()
    print(f"Epoch {epoch}: Avg WER Loss = {avg_loss:.4f}--------------------%%%%%%%%%%%%%%%%%%%@@@@@@@@@@@@@@@+++++++++++++++++++++")
    print()

    if epoch >= MAX_STEPS:
        break

# í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥
torch.save(coordinator.state_dict(), "coordinator.pth")
print("Coordinator saved!")

import matplotlib.pyplot as plt

# GPU í…ì„œë¥¼ CPUë¡œ ì˜®ê¸´ í›„ NumPy ë°°ì—´ë¡œ ë³€í™˜
avg_losses_cpu = [loss.cpu().item() if isinstance(loss, torch.Tensor) else loss for loss in avg_losses]

plt.plot(avg_losses_cpu)
plt.xlabel('Epoch')
plt.ylabel(f'Average {LOSS_FN}')
plt.title(f'Average {LOSS_FN} Over Epochs')
plt.show()
